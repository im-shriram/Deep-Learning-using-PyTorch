{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92823fb4",
   "metadata": {},
   "source": [
    "## **<u>Interpreting Loss Values in Machine Learning</u>**\n",
    "\n",
    "Think of loss as **a score that tells you \"how wrong\" your model is**. **Lower is better**, zero is perfect. But whether a loss value is \"huge\" depends entirely on context.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Regression Loss Functions\n",
    "\n",
    "#### Common Loss Functions:\n",
    "1. **Mean Absolute Error (MAE/L1 Loss)**\n",
    "2. **Mean Squared Error (MSE/L2 Loss)**\n",
    "3. **Root Mean Squared Error (RMSE)**\n",
    "\n",
    "#### **Mean Absolute Error (MAE)**\n",
    "```\n",
    "MAE = (1/n) × Σ|y_true - y_pred|\n",
    "```\n",
    "- **Interpretation:** \"On average, how far off is each prediction in the original units\"\n",
    "- **Example:** House price prediction with MAE = $25,000 means predictions are off by $25,000 on average\n",
    "- **Is 25,000 huge?** Depends:\n",
    "  - If average house price = $500,000 → 5% error → **Reasonable**\n",
    "  - If average house price = $100,000 → 25% error → **Huge**\n",
    "→ Take the RMSE of MSE first and then claculate the MAPE and compare\n",
    "\n",
    "#### **Mean Squared Error (MSE)**\n",
    "```\n",
    "MSE = (1/n) × Σ(y_true - y_pred)²\n",
    "```\n",
    "- **Interpretation:** \"Average of squared errors\" - penalizes large errors MORE\n",
    "- **Tricky part:** Units are squared (dollars², meters²) - not intuitive\n",
    "- **Example:** MSE = 6,250,000 for house prices\n",
    "  - This is $², so take square root → RMSE ≈ $2,500\n",
    "  - Actually small error for house prices!\n",
    "→ If the `Mean abslute percentage error (MAPE) < 5%` then the model has excellent performance\n",
    "\n",
    "#### **Rule of Thumb for Regression:**\n",
    "- Compare loss to **target variable range/scale**:\n",
    "  - Good: Loss < 5-10% of target range\n",
    "  - Bad: Loss > 20-30% of target range\n",
    "- Compare to **standard deviation** of target:\n",
    "  - If `loss (same unit as output column) > standard deviation`, model is worse than predicting the mean!\n",
    "  - `R2-score` - for comparing with mean prediction\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Classification Loss Functions\n",
    "\n",
    "#### Common Loss Functions:\n",
    "1. **Binary Cross-Entropy (Log Loss)**\n",
    "2. **Categorical Cross-Entropy**\n",
    "3. **Hinge Loss (SVM)**\n",
    "\n",
    "#### **Binary Cross-Entropy (Log Loss)**\n",
    "```\n",
    "Loss = -[y·log(p) + (1-y)·log(1-p)]\n",
    "```\n",
    "Where `y` is true label (0 or 1), `p` is predicted probability\n",
    "\n",
    "- **Range:** 0 to ∞ (but practically ~0 to ~10)\n",
    "- **Perfect prediction:** Loss = 0 (predicts 1.0 for class 1, 0.0 for class 0)\n",
    "- **Completely wrong:** Loss → ∞ (predicts 0.0 for class 1, or 1.0 for class 0)\n",
    "\n",
    "**Key Reference Points:**\n",
    "- **Random guessing (50% confidence):** Loss ≈ 0.693\n",
    "- **Pretty good model:** Loss < 0.2\n",
    "- **Excellent model:** Loss < 0.1\n",
    "- **Poor model:** Loss > 0.5\n",
    "- **Very bad model:** Loss > 1.0\n",
    "\n",
    "**Example Interpretation:**\n",
    "```\n",
    "Spam detection (binary classification):\n",
    "\n",
    "Model A: Loss = 0.05 → EXCELLENT (very confident correct predictions)\n",
    "Model B: Loss = 0.15 → GOOD (confident correct predictions)\n",
    "Model C: Loss = 0.4 → OKAY (better than random but not great)\n",
    "Model D: Loss = 1.2 → BAD (often confidently wrong)\n",
    "Model E: Loss = 0.693 → RANDOM GUESSING (no better than flipping coin)\n",
    "```\n",
    "\n",
    "#### **Categorical Cross-Entropy (Multi-class)**\n",
    "```\n",
    "Loss = -Σ y_i · log(p_i)\n",
    "```\n",
    "For C classes\n",
    "\n",
    "- **Random guessing baseline:**\n",
    "  - For 2 classes: ≈ 0.693\n",
    "  - For 3 classes: ≈ 1.099\n",
    "  - For 10 classes: ≈ 2.303\n",
    "  - Formula: `-log(1/C) = log(C)`\n",
    "- **Excellent model:** Loss << random baseline\n",
    "- **Bad model:** Loss near or above random baseline\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Universal Frameworks to Assess \"Hugeness\" - Compare to Baselines\n",
    "\n",
    "For any problem, ask:\n",
    "1. What's the loss if we predict the MEAN/MODE?\n",
    "2. What's the loss if we predict RANDOMLY?\n",
    "3. What's the loss of a SIMPLE RULE?\n",
    "→ Your model should beat all these!\n",
    "\n",
    "---\n",
    "\n",
    "### 4. The Most Important Principle: RELATIVE, NOT ABSOLUTE\n",
    "\n",
    "**Absolute loss values mean nothing without context!**\n",
    "\n",
    "#### Right Way to Think:\n",
    "WRONG thinking: \"My model has loss 1.5 → Is that huge?\"\n",
    "<u>RIGHT thinking</u>:\n",
    "1. My baseline (predicting mean) gives loss 2.0\n",
    "2. My simple linear model gives loss 1.8\n",
    "3. My complex model gives loss 1.5\n",
    "→ 25% improvement over baseline → GOOD!\n",
    "\n",
    "#### Also RIGHT thinking:\n",
    "In production, each 0.1 increase in log loss<br>\n",
    "costs us $10,000 in false positives.<br>\n",
    "Current loss is 0.3 → costing $30,000/month.<br>\n",
    "Target loss 0.2 → save $10,000/month.\"<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Remember:** A loss of 1,000 could be excellent (predicting planetary orbits in kilometers) or terrible (predicting exam scores out of 100). Context is everything!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
